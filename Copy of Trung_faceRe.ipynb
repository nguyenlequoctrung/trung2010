{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2547,"status":"ok","timestamp":1652510824331,"user":{"displayName":"Hoang Nguyen","userId":"10643278812292871885"},"user_tz":-420},"id":"IOVYe8ssDfLw","outputId":"db51bc31-a1db-416b-dd1e-297573523a9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIx_XlHgDzJv"},"outputs":[],"source":["import tensorflow as tf\n","\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import BatchNormalization\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.layers import ReLU\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import RMSprop,SGD\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","from keras.models import Sequential\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cTDwBqZYY2D","executionInfo":{"status":"ok","timestamp":1652510842201,"user_tz":-420,"elapsed":2943,"user":{"displayName":"Hoang Nguyen","userId":"10643278812292871885"}},"outputId":"1339d638-08d0-4f60-94ef-f61edf6e459d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1652510845681,"user":{"displayName":"Hoang Nguyen","userId":"10643278812292871885"},"user_tz":-420},"id":"sQBqVnoNqIvY","outputId":"b607bca6-79c3-4279-b807-ae483a0b1d7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 180 images belonging to 3 classes.\n","Found 57 images belonging to 3 classes.\n"]}],"source":["train_datagen = ImageDataGenerator(rescale=1./255.,\n","                                   rotation_range=10,\n","                                   width_shift_range=0.25,\n","                                   height_shift_range=0.25,\n","                                   shear_range=0.1,\n","                                   zoom_range=0.15,\n","                                   horizontal_flip=False)\n","training_set=train_datagen.flow_from_directory('/content/drive/MyDrive/face_rec/trainingset',\n","                                               target_size=(256,256),\n","                                               batch_size=256,\n","                                               class_mode ='categorical')\n","test_set=train_datagen.flow_from_directory('/content/drive/MyDrive/face_rec/testset',\n","                                               target_size=(256,256),\n","                                               batch_size=256,\n","                                               class_mode ='categorical')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1195,"status":"ok","timestamp":1652510850088,"user":{"displayName":"Hoang Nguyen","userId":"10643278812292871885"},"user_tz":-420},"id":"SHosJ8ZUEGve","outputId":"384eedb3-9bf7-427b-f4c8-15d4eab6caa0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 98, 98, 64)        640       \n","                                                                 \n"," batch_normalization (BatchN  (None, 98, 98, 64)       256       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 96, 96, 64)        36928     \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 96, 96, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 96, 96, 64)        102464    \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 96, 96, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 48, 48, 64)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 48, 48, 64)        0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 46, 46, 128)       73856     \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 46, 46, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 44, 44, 128)       147584    \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 44, 44, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 44, 44, 128)       409728    \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 44, 44, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 22, 22, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 22, 22, 128)       0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 20, 20, 256)       295168    \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 20, 20, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 10, 10, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_2 (Dropout)         (None, 10, 10, 256)       0         \n","                                                                 \n"," flatten (Flatten)           (None, 25600)             0         \n","                                                                 \n"," dense (Dense)               (None, 256)               6553856   \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 256)              1024      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               32896     \n","                                                                 \n"," batch_normalization_8 (Batc  (None, 128)              512       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_2 (Dense)             (None, 5)                 645       \n","                                                                 \n","=================================================================\n","Total params: 7,658,629\n","Trainable params: 7,656,197\n","Non-trainable params: 2,432\n","_________________________________________________________________\n"]}],"source":["model = Sequential()\n","\n","model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(100, 100, 1)))\n","model.add(BatchNormalization()) #----------------\n","model.add(Conv2D(64, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization()) #----------------\n","model.add(Conv2D(64, kernel_size=5, padding='same', activation='relu'))\n","model.add(BatchNormalization()) #----------------\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2)) #----------------\n","\n","model.add(Conv2D(128, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(128, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(128, kernel_size=5, padding='same', activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(256, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","\n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(BatchNormalization())\n","model.add(Dense(128))\n","model.add(BatchNormalization())\n","model.add(Dense(5, activation='softmax'))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1bHyJtsEN-u","outputId":"6b0542fe-a2c6-4df9-af68-55ef46417062"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n"]}],"source":["model = Sequential()\n","model.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(256,256,3)))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same'))\n","model.add(MaxPooling2D((2,2)))\n","model.add(Flatten())\n","model.add(Dense(128,activation='relu',kernel_initializer = 'he_uniform'))\n","#model.add(Dropout(0,2))\n","model.add(Dense(3,activation='Softmax'))\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.callbacks import EarlyStopping\n","#opt = SGD(lr = 0.01, momentum = 0.9)\n","model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])\n","callbacks=[EarlyStopping(monitor='val_loss',patience=100)]\n","history=model.fit(training_set,\n","                  steps_per_epoch=len(training_set),\n","                  batch_size = 256,\n","                  epochs=150,\n","                  validation_data=test_set,\n","                  validation_steps=len(test_set),\n","                  callbacks=callbacks,\n","                  verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5478,"status":"ok","timestamp":1652462439989,"user":{"displayName":"Hoang Nguyen","userId":"10643278812292871885"},"user_tz":-420},"id":"aFELLXJCCJ69","outputId":"14463178-938a-495f-d7bf-c6da2b7ecf73"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sai số kiểm tra là:  4.350195376900956e-05\n","Độ chính xác kiểm tra là:  1.0\n"]}],"source":["#đánh giá chất lượng của mô hình và vẽ lại\n","score = model.evaluate(test_set,verbose=0)\n","print('Sai số kiểm tra là: ',score[0])\n","print('Độ chính xác kiểm tra là: ',score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PelaFT3sZsBW"},"outputs":[],"source":["model.save('model_faceCNN.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"St5v8ZDdaVyR"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","model=load_model('model_faceCNN.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3uL0psIcbXsY"},"outputs":[],"source":["from tensorflow.keras.utils import load_img\n","from tensorflow.keras.utils import img_to_array\n","import matplotlib.pyplot as plt\n","test_img=load_img('',target_size=(256,256))\n","plt.imshow(test_img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5QG6NGZceOQ"},"outputs":[],"source":["from tensorflow.keras.utils import load_img\n","from tensorflow.keras.utils import img_to_array\n","import matplotlib.pyplot as plt\n","test_img=load_img('',target_size=(256,256))\n","plt.imshow(test_img)\n","import numpy as np\n","test_img= img_to_array(test_img)\n","test_img=test_img/255\n","test_img=np.expand_dims(test_img,axis=0)\n","result=model.predict(test_img)\n","if round(result[0][0])==1:\n","   prediction=\"trung\"\n","elif round(result[0][1])==1:\n","   prediction=\"anh\"\n","elif round(result[0][2])==1:\n","   prediction=\"luong\"  \n","print(prediction) \n","if  round(result[0][0])==1 or round(result[0][1])==1 or round(result[0][2])==1:\n","  print(\"Ket qua in ra:\",1)\n","else:\n","  print(\"ket qua in ra: \",0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWFu66D6f0cK"},"outputs":[],"source":["from tensorflow.keras.utils import load_img\n","from tensorflow.keras.utils import img_to_array\n","import matplotlib.pyplot as plt\n","test_img=load_img('',target_size=(256,256))\n","plt.imshow(test_img)\n","import numpy as np\n","test_img= img_to_array(test_img)\n","test_img=test_img/255\n","test_img=np.expand_dims(test_img,axis=0)\n","result=model.predict(test_img)\n","if round(result[0][0])==1:\n","   prediction=\"trung\"\n","elif round(result[0][1])==1:\n","   prediction=\"anh\"\n","elif round(result[0][2])==1:\n","   prediction=\"luong\"  \n","print(prediction) \n","if  round(result[0][0])==1 or round(result[0][1])==1 or round(result[0][2])==1:\n","  print(\"Ket qua in ra:\",1)\n","else:\n","  print(\"ket qua in ra: \",0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4dzFhmHbg0mp"},"outputs":[],"source":["import cv2\n","from tensorflow.keras.utils import load_img\n","from tensorflow.keras.utils import img_to_array\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","test_img=load_img('',target_size=(256,256))\n","#test_img=cv2.resize(test_img,(150,150),interpolation= cv2.INTER_LINEAR)\n","#resized_down = cv2.resize(image, down_points, interpolation= cv2.INTER_LINEAR)\n","\n","plt.imshow(test_img)\n","import numpy as np\n","test_img= img_to_array(test_img)\n","test_img=test_img/255\n","test_img=np.expand_dims(test_img,axis=0)\n","result=model.predict(test_img)\n","if round(result[0][0])==1:\n","   prediction=\"trung\"\n","elif round(result[0][1])==1:\n","   prediction=\"anh\"\n","elif round(result[0][2])==1:\n","   prediction=\"luong\"  \n","print(prediction) \n","if  round(result[0][0])==1 or round(result[0][1])==1 or round(result[0][2])==1:\n","  print(\"Ket qua in ra:\",1)\n","else:\n","  print(\"ket qua in ra: \",0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HmWdwoferQnq"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Copy of Trung_faceRe.ipynb","provenance":[{"file_id":"1yb8OGotsAi9SbHFEfKimBzlHkHPjW76X","timestamp":1652517978109},{"file_id":"1Qh-F8nJVdqp0AuQSbMqXcqDXJCdKpSUR","timestamp":1652455729070}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}